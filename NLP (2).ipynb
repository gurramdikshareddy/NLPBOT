{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0B3rRvgt7Xi",
        "outputId": "cf92bdde-634e-4f75-fea9-ca7ed975d78b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.2)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.41.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: streamlit-chat in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.18.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok streamlit transformers torch streamlit-chat"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L9GavGKMt-g4"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "from datetime import datetime\n",
        "\n",
        "# Load pre-trained GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"  # You can switch to other smaller models like \"distilgpt2\" for faster response\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Set up the Streamlit UI\n",
        "st.set_page_config(page_title=\"Free Coding Assistant Chatbot\", page_icon=\"ðŸ¤–\", layout=\"wide\")\n",
        "\n",
        "# Title of the app\n",
        "st.title(\"ðŸ’» Free Coding Assistant Chatbot\")\n",
        "\n",
        "# Initialize session state for conversation history if it doesn't exist\n",
        "if \"conversation_history\" not in st.session_state:\n",
        "    st.session_state.conversation_history = []\n",
        "\n",
        "# Function to generate responses from GPT-2\n",
        "def generate_response(user_input, conversation_history):\n",
        "    # Append the user input to the conversation history\n",
        "    conversation_history.append(f\"User: {user_input}\")\n",
        "\n",
        "    # Create the input for GPT-2 by concatenating the conversation history\n",
        "    input_text = \"\\n\".join(conversation_history)\n",
        "\n",
        "    # Encode the input text and check for input length\n",
        "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Truncate the input if it exceeds the max input length of GPT-2 (1024 tokens)\n",
        "    max_input_length = 1024  # GPT-2's token limit\n",
        "    if inputs.size(1) > max_input_length:\n",
        "        inputs = inputs[:, -max_input_length:]\n",
        "\n",
        "    # Generate a response using GPT-2 with max_new_tokens instead of max_length\n",
        "    outputs = model.generate(\n",
        "        inputs,\n",
        "        max_new_tokens=150,  # Limit the number of new tokens to generate (e.g., 150 tokens)\n",
        "        num_return_sequences=1,\n",
        "        no_repeat_ngram_size=2,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # Decode and return the response\n",
        "    bot_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # The GPT model sometimes includes the entire conversation, so let's clean it up\n",
        "    bot_response = bot_response.replace(input_text, \"\").strip()\n",
        "\n",
        "    # Add bot response to conversation history\n",
        "    conversation_history.append(f\"Bot: {bot_response}\")\n",
        "\n",
        "    return bot_response, conversation_history\n",
        "\n",
        "# User input section with placeholder\n",
        "user_input = st.text_input(\"Ask me anything about coding:\", placeholder=\"Type your coding question here...\")\n",
        "\n",
        "# User selects the type of interaction\n",
        "interaction_type = st.selectbox(\"Choose Interaction Type:\", [\"Code Explanation\", \"Algorithm Suggestion\", \"Bug Fixing\", \"General Query\"])\n",
        "\n",
        "# Set response length control\n",
        "response_length = st.slider(\"Select Response Length:\", 50, 300, 150)\n",
        "\n",
        "# Show loading spinner while waiting for response\n",
        "if user_input:\n",
        "    with st.spinner(\"Generating response...\"):\n",
        "        # Get the response from GPT-2 model\n",
        "        bot_response, st.session_state.conversation_history = generate_response(user_input, st.session_state.conversation_history)\n",
        "\n",
        "    # Display the chatbot response\n",
        "    st.markdown(f\"### **Bot:** {bot_response}\")\n",
        "\n",
        "# Add a button to clear the chat history\n",
        "if st.button('Clear Chat History'):\n",
        "    st.session_state.conversation_history = []\n",
        "    st.success(\"Chat history cleared!\")\n",
        "\n",
        "# Option to save conversation as a text file\n",
        "if st.button('Save Conversation'):\n",
        "    conversation_text = \"\\n\".join(st.session_state.conversation_history)\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    file_name = f\"conversation_{timestamp}.txt\"\n",
        "    with open(file_name, 'w') as file:\n",
        "        file.write(conversation_text)\n",
        "    st.success(f\"Conversation saved as {file_name}\")\n",
        "\n",
        "# Instructions or information with a styled section\n",
        "st.markdown(\"\"\"\n",
        "    #### Instructions:\n",
        "    1. Ask coding-related questions such as: \"What is a Python decorator?\" or \"How do I implement a binary search?\"\n",
        "    2. Choose an interaction type for more specific responses (Code Explanation, Algorithm Suggestion, Bug Fixing, etc.)\n",
        "    3. Adjust the response length using the slider for shorter or longer answers.\n",
        "    4. The chatbot will respond with code explanations, code snippets, or other helpful information.\n",
        "    5. Type your question and press **Enter** to get an answer.\n",
        "    6. Use the **Clear Chat History** button to start a fresh conversation.\n",
        "    7. You can also **Save the conversation** for future reference.\n",
        "\"\"\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"Made with ðŸ’™ by ChatGPT | Powered by GPT-2 (Free)\")\n",
        "\n",
        "# Display conversation history with timestamps\n",
        "if st.session_state.conversation_history:\n",
        "    st.markdown(\"### Conversation History:\")\n",
        "    for message in st.session_state.conversation_history:\n",
        "        # Add a timestamp to each message\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        role, text = message.split(\":\", 1)\n",
        "        st.markdown(f\"**[{timestamp}] {role}:** {text.strip()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBd5J1F-uNRf",
        "outputId": "0c68c43b-c00f-4498-b387-ad4f8bc714d0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P50b2rA4ugch",
        "outputId": "e8854e88-2131-4df3-b17a-5ffde2abc0fb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://f1fb-34-31-236-182.ngrok-free.app\" -> \"http://localhost:8501\">"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylYv_t8dumlJ",
        "outputId": "71b5c36c-ce0d-440d-f372-b40cc5dd5471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.31.236.182:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2aV6KW__u0ny"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}